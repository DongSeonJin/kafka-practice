package com.example.kafkaPractice.common.kafka.admin;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.admin.*;
import org.apache.kafka.common.KafkaFuture;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.config.ConfigResource;
import org.springframework.kafka.core.KafkaAdmin;
import org.springframework.stereotype.Service;

import java.util.Collection;
import java.util.Collections;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ExecutionException;

public interface KafkaAdminService {

    boolean createTopic(String topicName, int partitions, int replicationFactor);

    void describeTopic(String topicName);

    Set<String> getTopicList(String topicName);

    void describeTopicAsync(String topicName);

    void describeTopicConfig(String topicName);

    void deleteRecordsBeforeOffset(String topicName, int partition, long offset);

    @Service
    @Slf4j
    @RequiredArgsConstructor
    class KafkaAdminServiceImpl implements KafkaAdminService {
        private final KafkaAdmin kafkaAdmin;

        @Override
        public boolean createTopic(String topicName, int partitions, int replicationFactor) {
            try (AdminClient adminClient = AdminClient.create(kafkaAdmin.getConfigurationProperties())) {
                NewTopic newTopic = new NewTopic(topicName, partitions, (short) replicationFactor);

                // í† í”½ ìƒì„± ì˜µì…˜ (íƒ€ì„ì•„ì›ƒ 5ì´ˆ)
                CreateTopicsOptions options = new CreateTopicsOptions().timeoutMs(5000);
                // í† í”½ ìƒì„± ìš”ì²­ ë° ê²°ê³¼ í™•ì¸
                adminClient.createTopics(Collections.singleton(newTopic), options).all().get();
                log.info("í† í”½ '{}'ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.", topicName);
                return true;
            } catch (ExecutionException | InterruptedException e) {
                log.error("í† í”½ '{}' ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {}", topicName, e.getMessage());
                return false;
            }
        }

        @Override
        public void describeTopic(String topicName) {
            try (AdminClient adminClient = AdminClient.create(kafkaAdmin.getConfigurationProperties())) {
                DescribeTopicsResult result = adminClient.describeTopics(Collections.singleton(topicName));
                Map<String, TopicDescription> topicInfo = result.allTopicNames().get();

                log.info("í† í”½ ì •ë³´ [{}]: {}", topicName, topicInfo);
            } catch (ExecutionException | InterruptedException e) {
                log.error("í† í”½ '{}' ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {}", topicName, e.getMessage());
            }
        }

        @Override
        public Set<String> getTopicList(String topicName) {
            try (AdminClient adminClient = AdminClient.create(kafkaAdmin.getConfigurationProperties())) {
                // listTopics()ëŠ” ListTopicsResultë¥¼ ë°˜í™˜í•œë‹¤.
                ListTopicsResult topics = adminClient.listTopics();
                // .names()ë¥¼ í†µí•´ í† í”½ ì´ë¦„ Setì„ ë‹´ì€ KafkaFutureë¥¼ ì–»ëŠ”ë‹¤.
                KafkaFuture<Set<String>> names = topics.names();
                // .get()ìœ¼ë¡œ ê²°ê³¼ë¥¼ ê¸°ë‹¤ë ¤ ì‹¤ì œ Set<String>ì„ ê°€ì ¸ì˜¨ë‹¤.
                Set<String> topicNames = names.get();

                log.info("ğŸ” ì¡°íšŒëœ í† í”½ ìˆ˜: {}", topicNames.size());
                return topicNames;
            } catch (ExecutionException | InterruptedException e) {
                if (e instanceof InterruptedException) {
                    Thread.currentThread().interrupt();
                }
                log.error("í† í”½ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {}", e.getMessage());
                // ì‹¤íŒ¨ ì‹œì—ëŠ” null ëŒ€ì‹  ë¹„ì–´ìˆëŠ” ì»¬ë ‰ì…˜ì„ ë°˜í™˜í•˜ëŠ” ê²ƒì´ ë” ì•ˆì „í•˜ë‹¤.
                return Collections.emptySet();
            }
        }

        @Override
        public void describeTopicAsync(String topicName) {
            try (AdminClient adminClient = AdminClient.create(kafkaAdmin.getConfigurationProperties())) {
                DescribeTopicsResult result = adminClient.describeTopics(Collections.singleton(topicName));
                KafkaFuture<Map<String, TopicDescription>> future = result.allTopicNames();

                // whenComplete ì½œë°± ë“±ë¡
                future.whenComplete((topicInfoMap, throwable) -> {
                    if (throwable == null) {
                        TopicDescription description = topicInfoMap.get(topicName);
                        log.info("(Callback) í† í”½ ì •ë³´ [{}]: {}", topicName, description);
                    } else {
                        log.error("(Callback) í† í”½ '{}' ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {}", topicName, throwable.getMessage());
                    }
                });
            }
        }

        @Override
        public void describeTopicConfig(String topicName) {
            // 1. ì„¤ì • ì¡°íšŒì˜ ëŒ€ìƒì„ ì§€ì •í•˜ëŠ” ConfigResource ê°ì²´ ìƒì„±
            ConfigResource topicResource = new ConfigResource(ConfigResource.Type.TOPIC, topicName);
            log.info("í† í”½ '{}'ì˜ ì„¤ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤...", topicName);
            try (AdminClient adminClient = AdminClient.create(kafkaAdmin.getConfigurationProperties())) {
                DescribeConfigsResult result = adminClient.describeConfigs(Collections.singleton(topicResource));
                Map<ConfigResource, Config> configs = result.all().get();
                // 4. ì„¤ì •ê°’ ì¶œë ¥
                configs.forEach((resource, config) -> {
                    log.info("'{}'ì˜ ì„¤ì •:", resource.name());
                    Collection<ConfigEntry> entries = config.entries();
                    entries.forEach(entry -> {
                        // ê¸°ë³¸ê°’ì´ ì•„ë‹Œ ì„¤ì •ë§Œ ì¶œë ¥
                        if (!entry.isDefault()) {
                            log.info("  - {} = {}", entry.name(), entry.value());
                        }
                    });
                });
            } catch (Exception e) {
                log.error("í† í”½ '{}' ì„¤ì • ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {}", topicName, e.getMessage());
            }
        }

        @Override
        public void deleteRecordsBeforeOffset(String topicName, int partition, long offset) {
            TopicPartition topicPartition = new TopicPartition(topicName, partition);
            RecordsToDelete recordsToDelete = RecordsToDelete.beforeOffset(offset);
            Map<TopicPartition, RecordsToDelete> recordsToDeleteMap = Map.of(topicPartition, recordsToDelete);

            log.warn("ğŸ—‘ï¸ [AdminClient] í† í”½ '{}'-{} íŒŒí‹°ì…˜ì—ì„œ ì˜¤í”„ì…‹ {} ì´ì „ì˜ ë ˆì½”ë“œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤",
                    topicName, partition, offset);

            try (AdminClient adminClient = AdminClient.create(kafkaAdmin.getConfigurationProperties())) {
                adminClient.deleteRecords(recordsToDeleteMap).all().get();
                log.info("[AdminClient] ë ˆì½”ë“œ ì‚­ì œ ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
            } catch (Exception e) {
                log.error("[AdminClient] ë ˆì½”ë“œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {}", e.getMessage());
            }
        }
    }
}
